{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ySznhTSwNCFf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "imdb = pd.read_csv('movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "imdb = imdb.astype({'name': 'string', 'rating':'string','genre':'string', 'released':'string','director':'string','writer':'string','star':'string','country':'string','company':'string',})\n",
    "# drop any row with nan values\n",
    "imdb =imdb.dropna()\n",
    "imdb[['released_date','released_country']] = imdb['released'].str.slice(stop=-1).str.split(\" \\(\",n=1,expand = True)\n",
    "imdb['genre'] = imdb['genre'].str.lower()\n",
    "imdb.drop('released',axis=1,inplace=True)\n",
    "imdb['released_date'] = pd.to_datetime(imdb['released_date'])#,format=\"%B %d, %Y\")\n",
    "imdb['released_month'] = imdb['released_date'].dt.month\n",
    "imdb['released_day'] = imdb['released_date'].dt.day\n",
    "imdb['released_year'] = imdb['released_date'].dt.year\n",
    "imdb['released_day_of_week'] = imdb['released_date'].dt.dayofweek\n",
    "imdb['GBratio'] = imdb[\"gross\"]/imdb[\"budget\"]\n",
    "\n",
    "# (gross - budget )/ budget is bigger than 20%  we call successful\n",
    "imdb['success'] =imdb['GBratio']>1.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Get popular directors, actors, actresses from IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import math\n",
    "def get_popular_director_list():\n",
    "    url = \"https://www.imdb.com/list/ls026411399/?sort=list_order,asc&mode=detail\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    results_page = BeautifulSoup(response.content)\n",
    "    temp =results_page.find('span',{\"class\":\"pagination-range\"}).get_text()\n",
    "    last_page_temp = temp.strip().split(' ')\n",
    "    last_page_number = math.ceil(int(last_page_temp[4])/int(last_page_temp[2]))\n",
    "    \n",
    "    director_list = list()\n",
    "    for i in range(last_page_number):\n",
    "        durl = url+\"&page=\"+str(i+1)\n",
    "        response = requests.get(durl)\n",
    "        soup = BeautifulSoup(response.text)\n",
    "        director_list_temp=[j.find('a').get_text()[1:].replace('\\n','') for j in soup.find_all('h3',{\"class\":\"lister-item-header\"})]\n",
    "        director_list.extend(director_list_temp)\n",
    "    return director_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import math\n",
    "def get_popular_actor_list():\n",
    "    url = \"https://www.imdb.com/list/ls022928819/?sort=list_order,asc&mode=detail\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    results_page = BeautifulSoup(response.content)\n",
    "    temp =results_page.find('span',{\"class\":\"pagination-range\"}).get_text()\n",
    "    last_page_temp = temp.strip().split(' ')\n",
    "    last_page_number = math.ceil(int(last_page_temp[4])/int(last_page_temp[2]))\n",
    "    \n",
    "    actor_list = list()\n",
    "    for i in range(last_page_number):\n",
    "        acturl = url+\"&page=\"+str(i+1)\n",
    "        response = requests.get(acturl)\n",
    "        soup = BeautifulSoup(response.text)\n",
    "        actor_list_temp=[j.find('a').get_text()[1:].replace('\\n','') for j in soup.find_all('h3',{\"class\":\"lister-item-header\"})]\n",
    "        actor_list.extend(actor_list_temp)\n",
    "        \n",
    "    return actor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import math\n",
    "def get_popular_actress_list():\n",
    "    url = \"https://www.imdb.com/list/ls022928836/?sort=list_order,asc&mode=detail\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    results_page = BeautifulSoup(response.content)\n",
    "    temp =results_page.find('span',{\"class\":\"pagination-range\"}).get_text()\n",
    "    last_page_temp = temp.strip().split(' ')\n",
    "    last_page_number = math.ceil(int(last_page_temp[4])/int(last_page_temp[2]))\n",
    "    actress_list = list()\n",
    "    for i in range(last_page_number):\n",
    "        actrssurl = url+\"&page=\"+str(i+1)\n",
    "        response = requests.get(actrssurl)\n",
    "        soup = BeautifulSoup(response.text)\n",
    "        actress_list_temp=[j.find('a').get_text()[1:].replace('\\n','') for j in soup.find_all('h3',{\"class\":\"lister-item-header\"})]\n",
    "        actress_list.extend(actress_list_temp)\n",
    "    return actress_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we choose top 200 popular directors from popular director list, and categorize our directors in our dataset into popular and popular directors\n",
    "# likewise, we do this for popular actors and actresses. \n",
    "\n",
    "popular_directors = get_popular_director_list()[:200]\n",
    "star_list = get_popular_actor_list()[:200] + get_popular_actress_list()[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb['director_popularity'] = np.array([1 if i in popular_directors else 0 for i in imdb.director])\n",
    "imdb['star_popularity'] = np.array([1 if i in star_list else 0 for i in imdb.star])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb.drop(['director','star','gross','budget'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "# statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from group_lasso.utils import extract_ohe_groups\n",
    "%matplotlib inline\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5421 entries, 0 to 7652\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   rating                5421 non-null   string \n",
      " 1   genre                 5421 non-null   string \n",
      " 2   country               5421 non-null   string \n",
      " 3   company               5421 non-null   string \n",
      " 4   runtime               5421 non-null   float64\n",
      " 5   released_country      5421 non-null   string \n",
      " 6   released_month        5421 non-null   int64  \n",
      " 7   released_day          5421 non-null   int64  \n",
      " 8   released_day_of_week  5421 non-null   int64  \n",
      " 9   GBratio               5421 non-null   float64\n",
      " 10  success               5421 non-null   bool   \n",
      " 11  director_popularity   5421 non-null   int32  \n",
      " 12  star_popularity       5421 non-null   int32  \n",
      "dtypes: bool(1), float64(2), int32(2), int64(3), string(5)\n",
      "memory usage: 513.5 KB\n"
     ]
    }
   ],
   "source": [
    "# drop released_year because we cant go back. also drop score, votes because these are consequence once a movie is released\n",
    "# imdb_temp_bf_le is the dataset for Machine learning before labelencoding\n",
    "imdb_temp_bf_le =  imdb.drop(['name', 'score', 'votes', 'year','released_year', 'writer', 'released_date'], inplace = False, axis=1)\n",
    "imdb_temp_bf_le.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imdb_temp_bf_le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labelencoding Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(imdb['rating'])\n",
    "le_name_mapping_rating = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "le.fit(imdb['genre'])\n",
    "le_name_mapping_genre = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "le.fit(imdb['country'])\n",
    "le_name_mapping_country = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "le.fit(imdb['company'])\n",
    "le_name_mapping_company = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "le.fit(imdb['released_country'])\n",
    "le_name_mapping_released_country = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "day_of_week_mapping = {'Monday':0, 'Tuesday':1, 'Wednesday': 2, 'Thursday':3, 'Friday': 4, 'Saturday': 5, 'Sunday':6}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoder and one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "imdb['rating'] = le.fit_transform(imdb['rating'])\n",
    "imdb['genre'] = le.fit_transform(imdb['genre'])\n",
    "imdb['country'] = le.fit_transform(imdb['country'])\n",
    "imdb['company'] = le.fit_transform(imdb['company'])\n",
    "imdb['released_country'] = le.fit_transform(imdb['released_country'])\n",
    "\n",
    "categorical_column = ['rating','genre','country','company', 'released_country','director_popularity','star_popularity']\n",
    "non_categorical_column =['runtime','released_month','released_day','released_day_of_week']\n",
    "# imdb_temp_af_le is the dataset we use for machine learning after label encoding\n",
    "imdb_temp_af_le =  imdb.drop(['name', 'score', 'votes', 'year','released_year', 'writer', 'released_date'], inplace = False, axis=1)\n",
    "\n",
    "x = imdb_temp_af_le.loc[:,categorical_column +non_categorical_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = imdb_temp_af_le.loc[:,categorical_column+non_categorical_column]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "\n",
    "#The code below makes a column transformer object that scales the non-categorical columns\n",
    "# and one hot encodes the categorical columns\n",
    "preprocess = make_column_transformer((StandardScaler(),non_categorical_column), \n",
    "    (OneHotEncoder(categories=\"auto\",drop=\n",
    "                   'first'), categorical_column)\n",
    "\n",
    ")\n",
    "\n",
    "#The next step prepares the independent variables\n",
    "X = preprocess.fit_transform(x).toarray()\n",
    "y1 = imdb['GBratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imdb_temp_af_le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X, y1, test_size=0.30, random_state=42)\n",
    "y_train = y_train\n",
    "y_test = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoCV(cv=5, random_state=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_re = LassoCV(cv=5, random_state=0)\n",
    "lasso_re.fit(x_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:  5.772611413934554\n",
      "r squared:  -0.07851514906897394\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score\n",
    "pred_test_lasso= lasso_re.predict(x_test)\n",
    "print(\"Mean squared error: \",np.sqrt(mean_squared_error(y_test,pred_test_lasso))) \n",
    "print(\"r squared: \",r2_score(y_test, pred_test_lasso))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = imdb['success']\n",
    "y2 = imdb['success'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3794, 1599) (3794,)\n",
      "(1627, 1599) (1627,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y2,test_size=0.30, random_state=42)\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(random_state=42)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "model_1 = SGDClassifier(random_state=42,max_iter=1000)\n",
    "model_1.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:  0.8062730627306273\n",
      "testing accuracy:  0.6539643515673018\n",
      "confusion matrix:\n",
      "[[188 420]\n",
      " [143 876]]\n",
      "precision:  0.6759259259259259\n",
      "recall:  0.8596663395485771\n",
      "f1 score:  0.7568034557235421\n"
     ]
    }
   ],
   "source": [
    "#get training and testing data accuracy\n",
    "train_acc_model_1 = model_1.score(x_train,y_train)\n",
    "test_acc_model_1 = model_1.score(x_test,y_test)\n",
    "                        \n",
    "print(\"training accuracy: \",train_acc_model_1)\n",
    "print(\"testing accuracy: \",test_acc_model_1)\n",
    "print(\"confusion matrix:\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score,recall_score,precision_score\n",
    "\n",
    "#Get testing predictions\n",
    "test_pred_model_1 = model_1.predict(x_test)\n",
    "\n",
    "#Get confusion matrix\n",
    "cfm_model_1 = confusion_matrix(y_test,test_pred_model_1)\n",
    "print(cfm_model_1)\n",
    "\n",
    "#Get f1 score, precision and recall\n",
    "f1_model_1 = f1_score(y_test,test_pred_model_1)\n",
    "precision_model_1 = precision_score(y_test,test_pred_model_1)\n",
    "recall_model_1 = recall_score(y_test,test_pred_model_1)\n",
    "\n",
    "print(\"precision: \",precision_model_1)\n",
    "print(\"recall: \",recall_model_1)\n",
    "print(\"f1 score: \",f1_model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import average_precision_score,make_scorer\n",
    "from sklearn.metrics import confusion_matrix,f1_score,precision_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'class_weight': [{1: 5}],\n",
       "                         'min_samples_split': (200, 400),\n",
       "                         'n_estimators': (100, 200)},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "     'n_estimators':(100,200), #the number of trees\n",
    "     'min_samples_split': (200, 400),\n",
    "    'class_weight': [{1:5}]\n",
    "     #'min_samples_leaf': (20,40,60)\n",
    "}\n",
    "gs_clf = GridSearchCV(RandomForestClassifier(random_state=42),parameters,cv=5,n_jobs=-1,\n",
    "                      scoring='f1')\n",
    "#                     scoring=make_scorer(average_precision_score))\n",
    "gs_clf.fit(x_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': {1: 5}, 'min_samples_split': 400, 'n_estimators': 200}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight={1: 5}, min_samples_split=400,\n",
       "                       n_estimators=200, random_state=42)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Parameterize the random forest model and fit the data\n",
    "model_2 = RandomForestClassifier(random_state=42,n_estimators=200,min_samples_split=400,class_weight={1:5})#,max_depth=5,min_samples_leaf=2000,min_samples_split=4000,class_weight={1:5})\n",
    "model_2.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:  0.6404849762783342\n",
      "testing accuracy:  0.6287645974185617\n",
      "confusion matrix:\n",
      "[[   5  603]\n",
      " [   1 1018]]\n",
      "precision:  0.6280074028377545\n",
      "recall:  0.9990186457311089\n",
      "f1 score:  0.7712121212121211\n"
     ]
    }
   ],
   "source": [
    "#get training and testing data accuracy\n",
    "train_acc_model_2 = model_2.score(x_train,y_train)\n",
    "test_acc_model_2 = model_2.score(x_test,y_test)\n",
    "                        \n",
    "print(\"training accuracy: \",train_acc_model_2)\n",
    "print(\"testing accuracy: \",test_acc_model_2)\n",
    "print(\"confusion matrix:\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Get testing predictions\n",
    "test_pred_model_2 = model_2.predict(x_test)\n",
    "\n",
    "#Get confusion matrix\n",
    "cfm_model_2 = confusion_matrix(y_test,test_pred_model_2)\n",
    "print(cfm_model_2)\n",
    "\n",
    "#Get f1 score, precision and recall\n",
    "f1_model_2 = f1_score(y_test,test_pred_model_2)\n",
    "precision_model_2 = precision_score(y_test,test_pred_model_2)\n",
    "recall_model_2 = recall_score(y_test,test_pred_model_2)\n",
    "\n",
    "print(\"precision: \",precision_model_2)\n",
    "print(\"recall: \",recall_model_2)\n",
    "print(\"f1 score: \",f1_model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook, show \n",
    "from bokeh.plotting import figure\n",
    "from bokeh.layouts import gridplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_one_roc_curve(fpr,tpr,thresholds,auc,model):\n",
    "    #Set up the ColumnDataSource object\n",
    "    from bokeh.models import LabelSet, ColumnDataSource,HoverTool\n",
    "    import pandas as pd\n",
    "    df_d = pd.DataFrame([fpr,tpr,thresholds]).transpose()\n",
    "    df_d.columns = [\"fpr\",\"tpr\",\"threshold\"]\n",
    "    source = ColumnDataSource(df_d)    \n",
    "    \n",
    "    \n",
    "    # Create custom HoverTool -- we'll make one for each curve\n",
    "    hover_ROC = HoverTool(names=['ROC'], tooltips=[(\"TPR\", \"@tpr\"), \n",
    "                                                   (\"FPR\", \"@fpr\"), \n",
    "                                                   (\"Thresh\", \"@threshold\"),\n",
    "                                                  ])\n",
    "\n",
    "    # Create the tools\n",
    "    p_tools_ROC = [hover_ROC, 'crosshair', 'zoom_in', 'zoom_out', 'save', 'reset', 'tap', 'box_zoom']\n",
    "\n",
    "    p1 = figure(title=\"ROC Curve for \"+model, tools=p_tools_ROC,x_range=(0,1),y_range=(0,1))\n",
    "\n",
    "    p1.xaxis.axis_label = 'False Positive Rate' \n",
    "    p1.yaxis.axis_label = 'True Positive Rate'\n",
    "\n",
    "    # plot curve and datapts\n",
    "    p1.line('fpr', 'tpr', line_width=1, color=\"blue\", source=source)\n",
    "    p1.circle('fpr', 'tpr', size=3, color=\"orange\", legend_label='auc='+auc, source=source, name='ROC')\n",
    "\n",
    "    # Plot chance (tpr = fpr 45 degrees line)\n",
    "    p1.line([0, 1], [0, 1], line_dash='dashed', line_width=0.5, color='black', name='Chance')\n",
    "\n",
    "    # Keep the legend at the bottom \n",
    "    p1.legend.location = \"bottom_right\"\n",
    "    \n",
    "    #Return the figure\n",
    "    return p1\n",
    "    \n",
    "    \n",
    "def draw_roc_curves():\n",
    "  \n",
    "    #Get the predicted probabilities for each model\n",
    "    #Note that we can't just use predictions because they will be 0,1 values\n",
    "    from sklearn.model_selection import cross_val_predict\n",
    "    predic_prob_model_1 = cross_val_predict(model_1,x_test,y_test,cv=5,method=\"decision_function\")\n",
    "    predic_prob_model_2 = model_2.predict_proba(x_test)\n",
    "\n",
    "\n",
    "    #Get the AUC for each model\n",
    "    from sklearn.metrics import roc_curve, roc_auc_score\n",
    "    auc_m1 = roc_auc_score(y_test,predic_prob_model_1)\n",
    "    auc_m2 = roc_auc_score(y_test,predic_prob_model_2[:,1])\n",
    "    \n",
    "    #Format auc to two decimal places\n",
    "    auc_m1 = \"%1.2f\"%auc_m1\n",
    "    auc_m2 = \"%1.2f\"%auc_m2\n",
    "  \n",
    "    #Using the predicted probabilities, get the roc curves\n",
    "    #fpr = false positive rate\n",
    "    #tpr = true positive rate\n",
    "    #thresholds = threshold choices\n",
    "    #The ROC curve reports the fpr and tpr for each chosen threshold\n",
    "    fpr_m1,tpr_m1,thresholds_m1 = roc_curve(y_test,predic_prob_model_1)\n",
    "    fpr_m2,tpr_m2,thresholds_m2 = roc_curve(y_test,predic_prob_model_2[:,1])\n",
    "\n",
    "    #Draw the various ROC Curves\n",
    "    p1=draw_one_roc_curve(fpr_m1,tpr_m1,thresholds_m1,auc_m1,\"SGD Model\")\n",
    "    p2=draw_one_roc_curve(fpr_m2,tpr_m2,thresholds_m2,auc_m2,\"Random Forest Model\")\n",
    "\n",
    "    #Set up the grid for all the curves\n",
    "    grid = gridplot([[p1,p2]],sizing_mode=\"scale_both\",merge_tools=True)\n",
    "\n",
    "    #Show the curves\n",
    "    show(grid)\n",
    "\n",
    "#Call the function\n",
    "draw_roc_curves()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PR curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_one_PR_curve(precision,recall,thresholds,f1_score ,model):\n",
    "    from bokeh.models import LabelSet, ColumnDataSource, Label\n",
    "    import pandas as pd\n",
    "\n",
    "    df_d = pd.DataFrame([recall,precision,thresholds]).transpose()\n",
    "    df_d.columns = [\"recall\",\"precision\",\"threshold\"]\n",
    "\n",
    "    source = ColumnDataSource(df_d)\n",
    "\n",
    "    p_tools = ['crosshair', 'zoom_in', 'zoom_out', 'save', 'reset', 'tap', 'box_zoom']\n",
    "\n",
    "    #Figure\n",
    "    p = figure(title=\"PR Curve for \"+model, tools=p_tools)\n",
    "    p.xaxis.axis_label = 'threshold' \n",
    "    p.yaxis.axis_label = 'precision/recall'\n",
    "    \n",
    "    #Add lines for precision and recall\n",
    "    p.line('threshold', 'precision', line_width=1, color=\"blue\", source=source,legend_label=\"precision\")\n",
    "    p.line('threshold', 'recall', line_width=1, color=\"red\", source=source,legend_label=\"recall\")\n",
    "    \n",
    "    f1_label = Label(x=1.0, y=.70, x_units='screen', y_units='screen', text='F1 Score='+f1_score, render_mode='css',\n",
    "      border_line_color='black', border_line_alpha=0.0,\n",
    "      background_fill_color='white', background_fill_alpha=1.0)\n",
    "    \n",
    "    p.add_layout(f1_label)\n",
    "   \n",
    "    # legend location\n",
    "    p.legend.location = \"bottom_left\"\n",
    "    return p\n",
    "\n",
    "def draw_pr_curves():\n",
    "    #Get the predicted probabilities for each model\n",
    "    #Note that we can't just use predictions because they will be 0,1 values\n",
    "    from sklearn.model_selection import cross_val_predict\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "    predic_prob_model_1 = cross_val_predict(model_1,x_test,y_test,cv=5,method=\"decision_function\")\n",
    "    predic_prob_model_2 = model_2.predict_proba(x_test)\n",
    "\n",
    "    #Get precisions and recalls\n",
    "    precision_1,recall_1,thresholds_1 = precision_recall_curve(y_test,predic_prob_model_1)\n",
    "    precision_2,recall_2,thresholds_2 = precision_recall_curve(y_test,predic_prob_model_2[:,1])\n",
    "\n",
    "    #draw the curves\n",
    "    p1 = draw_one_PR_curve(precision_1,recall_1,thresholds_1,str(\"%1.3f\"%f1_model_1),\"SGD Model\")\n",
    "    p2 = draw_one_PR_curve(precision_2,recall_2,thresholds_2,str(\"%1.3f\"%f1_model_2),\"Random Forest Model\")\n",
    "\n",
    "    #Set up the grid for all the curves\n",
    "    grid = gridplot([[p1,p2]],sizing_mode=\"scale_both\",merge_tools=True)\n",
    "\n",
    "    #Show the curves\n",
    "    show(grid)\n",
    "\n",
    "draw_pr_curves()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Movie Prediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since Random Forest gives us better F1 score, we'll use Random Forest to do prediciton."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input all the info as a datapoint, labelencoding using the mapping list and run the ranmdom forest to predict if a movie would be successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input the rating: PG-13\n",
      "Input the genre: action\n",
      "Which country made this movie: United States\n",
      "Input the production company: Columbia Pictures\n",
      "Where is this movie released: United States\n",
      "Who is the director: Jon Watts\n",
      "Who is the first main actor or actress:Zendaya\n",
      "Who is the second main actor or actress: Benedict Cumberbatch\n",
      "How long is the movie in minutes, please only type number:  150\n",
      "Which month is the movie released, please type number: 12\n",
      "Which day of that month is the movie released, please type number: 17\n",
      "Which day of week is the movie released: Friday\n"
     ]
    }
   ],
   "source": [
    "#We are predict Spider Man: No Way Home, the info is the following: \n",
    "# Rating: PG-13; Genre : Action; Runtime: 2 hours 30 min;\n",
    "# Release date: December 17, 2021 (United States); Countries of origin: United States; Production companies: Columbia Pictures;\n",
    "# Director:Jon Watts; Star: Zendaya, Benedict Cumberbatch, Tom Holland\n",
    "rating_0 = str(input('Input the rating: '))\n",
    "rating_0 = int(le_name_mapping_rating[rating_0])\n",
    "genre_0 =  str(input('Input the genre: ')).lower()\n",
    "genre_0 = int(le_name_mapping_genre[genre_0])\n",
    "country_0 = str(input('Which country made this movie: ')) \n",
    "country_0 = int(le_name_mapping_country[country_0])\n",
    "company_0 = str(input('Input the production company: '))\n",
    "company_0 = int(le_name_mapping_company[company_0])\n",
    "released_country_0 = str(input('Where is this movie released: '))\n",
    "released_country_0 = int(le_name_mapping_released_country[released_country_0])\n",
    "director_0 = str(input('Who is the director: '))\n",
    "director_popularity_0 = int(1 if director_0 in popular_directors else 0)    \n",
    "star_01 = str(input('Who is the first main actor or actress:'))\n",
    "star_01 = 1 if star_01 in star_list else 0\n",
    "star_02 = str(input('Who is the second main actor or actress: '))\n",
    "star_02 = 1 if star_02 in star_list else 0\n",
    "star_popularity_0 = int(1 if (star_01 + star_02) >=1 else 0)  \n",
    "runtime_0 = float(input('How long is the movie in minutes, please only type number:  '))\n",
    "released_month_0 = int(input('Which month is the movie released, please type number: '))\n",
    "released_day_0 = int(input('Which day of that month is the movie released, please type number: '))\n",
    "released_day_of_week_0 = str(input('Which day of week is the movie released: '))\n",
    "released_day_of_week_0 = int(day_of_week_mapping[released_day_of_week_0])\n",
    "\n",
    "import numpy as np\n",
    "data_point = np.array([(rating_0, genre_0,country_0,company_0,released_country_0,director_popularity_0,star_popularity_0,runtime_0, released_month_0, released_day_0,released_day_of_week_0)],\n",
    "    dtype = [('rating','int64'),('genre', 'int64'),('country','int64'),('company','int64'),('released_country','int64'),('director_popularity','int32'),('star_popularity','int32'),\n",
    "    ('runtime','float64'),('released_month','int64'),('released_day','int64'),('released_day_of_week','int64')])\n",
    "pd_data_point = pd.DataFrame(data_point)\n",
    "x_new =x.append(pd_data_point, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode the new datapoint and standardize it\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "import numpy as np\n",
    "#The code below makes a column transformer object that scales the non-categorical columns\n",
    "# and one hot encodes the categorical columns\n",
    "preprocess = make_column_transformer((StandardScaler(),non_categorical_column), \n",
    "    (OneHotEncoder(categories=\"auto\",drop='first'), categorical_column))\n",
    "\n",
    "#The next step prepares the independent variables\n",
    "X = preprocess.fit_transform(x_new).toarray()\n",
    "datapoint_x = X[-1].reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful Movie? [ True]\n"
     ]
    }
   ],
   "source": [
    "test_pred_model_2 = model_2.predict(datapoint_x)\n",
    "\n",
    "print('Successful Movie?', np.array2string(test_pred_model_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "data_project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
